{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a621b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers: [100, 100, 100, 276]\n",
      "Activation: <function leaky_relu at 0x7f5b607f0f28>\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "import numpy as np\n",
    "import haiku as hk\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from typing import Callable, Iterable, Optional\n",
    "import optax\n",
    "from tqdm import trange\n",
    "from jax.config import config\n",
    "from sklearn.metrics import r2_score\n",
    "from haiku_custom_forward import _custom_forward_fn, schedule_lr, loss_fn, accuracy, update, output_size, activation\n",
    "from plotVis import *\n",
    "\n",
    "max_grad_norm = 0.1\n",
    "n_epochs = 1000\n",
    "lr = 1e-3\n",
    "decay = 5e-3\n",
    "batch_size = 1000\n",
    "print(f'Layers: {output_size}')\n",
    "print(f'Activation: {activation}')\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "dtype=jnp.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0194a0fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z54\n",
      "(89, 3)\n",
      "(358, 276)\n",
      "(89, 276)\n",
      "(768, 276)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "input_overplot() missing 1 required positional argument: 'X_vali'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-79ef967c376d>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 40\u001B[0;31m \u001B[0minput_overplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m: input_overplot() missing 1 required positional argument: 'X_vali'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load Train and Test Data\n",
    "'''\n",
    "redshift = 5.4 #choose redshift from\n",
    "num = '_training_768'\n",
    "test_num = '_test_89'\n",
    "vali_num = '_vali_358'\n",
    "# get the appropriate string and pathlength for chosen redshift\n",
    "zs = np.array([5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6.0])\n",
    "z_idx = np.argmin(np.abs(zs - redshift))\n",
    "z_strings = ['z54', 'z55', 'z56', 'z57', 'z58', 'z59', 'z6']\n",
    "z_string = z_strings[z_idx]\n",
    "dir_lhs = '/home/zhenyujin/igm_emulator/igm_emulator/emulator/GRID/'\n",
    "print(z_string)\n",
    "\n",
    "X = dill.load(open(dir_lhs + f'{z_string}_param{num}.p', 'rb')) # load normalized cosmological parameters from grab_models.py\n",
    "X_test = dill.load(open(dir_lhs + f'{z_string}_param{test_num}.p', 'rb'))\n",
    "X_vali = dill.load(open(dir_lhs + f'{z_string}_param{vali_num}.p', 'rb'))\n",
    "meanX = X.mean(axis=0)\n",
    "stdX = X.std(axis=0)\n",
    "X_train = (X - meanX) / stdX\n",
    "X_test = (X_test - meanX) / stdX\n",
    "X_vali = (X_vali - meanX) / stdX\n",
    "print(X_test.shape)\n",
    "\n",
    "Y = dill.load(open(dir_lhs + f'{z_string}_model{num}.p', 'rb'))\n",
    "Y_test = dill.load(open(dir_lhs + f'{z_string}_model{test_num}.p', 'rb'))\n",
    "Y_vali = dill.load(open(dir_lhs + f'{z_string}_model{vali_num}.p', 'rb'))\n",
    "meanY = Y.mean(axis=0)\n",
    "stdY = Y.std(axis=0)\n",
    "Y_train = (Y - meanY) / stdY\n",
    "Y_test = (Y_test - meanY) / stdY\n",
    "Y_vali = (Y_vali - meanY) / stdY\n",
    "print(Y_vali.shape)\n",
    "print(Y_test.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "input_overplot(X_train,X_test, X_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cd62f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Build custom haiku Module\n",
    "'''\n",
    "custom_forward = hk.without_apply_rng(hk.transform(_custom_forward_fn))\n",
    "init_params = custom_forward.init(rng=42, x=X_train)\n",
    "preds = custom_forward.apply(params=init_params, x=X_train)\n",
    "n_samples = X_train.shape[0]\n",
    "total_steps = n_epochs*n_samples + n_epochs\n",
    "\n",
    "optimizer = optax.chain(optax.clip_by_global_norm(max_grad_norm),\n",
    "                        optax.adam(learning_rate=schedule_lr(lr,total_steps))\n",
    "                        )\n",
    "opt_state = optimizer.init(init_params)\n",
    "train_overplot(preds, Y_train, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c6a26b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params_grads_distribution(loss_fn,init_params,X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75496050",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Training Loop + Visualization of params\n",
    "'''\n",
    "#params_grads_distribution(loss_fn,init_params,X_train,Y_train)\n",
    "\n",
    "best_loss = np.inf\n",
    "validation_loss = []\n",
    "training_loss = []\n",
    "early_stopping_counter = 0\n",
    "pv = 100\n",
    "params = init_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0536cbb8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with trange(n_epochs) as t:\n",
    "        for step in t:\n",
    "            # optimizing loss by update function\n",
    "            params, opt_state, batch_loss, grads = update(params, opt_state, X_train, Y_train, optimizer)\n",
    "\n",
    "            #if step % 100 == 0:\n",
    "                #plot_params(params)\n",
    "\n",
    "            # compute training & validation loss at the end of the epoch\n",
    "            l = loss_fn(params, X_vali, Y_vali)\n",
    "            training_loss.append(batch_loss)\n",
    "            validation_loss.append(l)\n",
    "\n",
    "            # update the progressbar\n",
    "            t.set_postfix(loss=validation_loss[-1])\n",
    "\n",
    "            # early stopping condition\n",
    "            if l <= best_loss:\n",
    "                best_loss = l\n",
    "                early_stopping_counter = 0\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "            if early_stopping_counter >= pv:\n",
    "                break\n",
    "\n",
    "    print(f'Reached max number of epochs in this batch. Validation loss ={best_loss}. Training loss ={batch_loss}')\n",
    "    best_params = params\n",
    "    print(f'Model saved.')\n",
    "    print(f'early_stopping_counter: {early_stopping_counter}')\n",
    "    print(f'accuracy: {jnp.mean(accuracy(params, X_test, Y_test, meanY, stdY))}')\n",
    "    print(f'Test Loss: {loss_fn(params, X_test, Y_test)}')\n",
    "    plt.plot(range(len(validation_loss)), validation_loss, label=f'vali loss:{best_loss:.4f}')  # plot validation loss\n",
    "    plt.plot(range(len(training_loss)), training_loss, label=f'train loss:{batch_loss: .4f}')  # plot training loss\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e9ad15",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from plotVis import *\n",
    "'''\n",
    "Prediction overplots: Training And Test\n",
    "'''\n",
    "preds = custom_forward.apply(params=best_params, x=X_train)\n",
    "train_overplot(preds, Y_train, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ecc7aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_preds = custom_forward.apply(params, X_test)\n",
    "test_loss = loss_fn(params, X_test, Y_test)\n",
    "test_R2 = r2_score(test_preds.squeeze(), Y_test)\n",
    "\n",
    "test_overplot(test_preds, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b1b93b",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Accuracy + Results\n",
    "'''\n",
    "delta = np.asarray(accuracy(best_params, X_test, Y_test, meanY, stdY))\n",
    "print('Test R^2 Score: {}\\n'.format(test_R2))  # R^2 score: ranging 0~1, 1 is good model\n",
    "print(f'accuracy: {jnp.mean(delta)*100}')\n",
    "\n",
    "plot_residue(delta)\n",
    "bad_learned_plots(delta,X_test,Y_test,test_preds)\n",
    "plot_error_distribution(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faff0d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8f4604",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}